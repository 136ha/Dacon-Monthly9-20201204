{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "b378958a9606ac48fe0dc54e24bed4cd503e0ac7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train texts:  54879\n",
      "Number of test texts:  19617\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\", encoding = 'utf-8')\n",
    "test = pd.read_csv(\"test_x.csv\", encoding = 'utf-8')\n",
    "\n",
    "print(\"Number of train texts: \", train.shape[0])\n",
    "print(\"Number of test texts: \", test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "807e734e0ce617480c824f8bf26f0672f38397d5"
   },
   "outputs": [],
   "source": [
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    if file == 'embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='utf-8') if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "44662473bad36713bbe610e84039145c81e941b2"
   },
   "outputs": [],
   "source": [
    "glove = 'embeddings/glove.840B.300d/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7a0a98920daa420bf37a910739cda6bc716ba872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting GloVe embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting GloVe embedding\")\n",
    "embed_glove = load_embed(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c362fc1868aaa53dfc0bd91d453419815eba7c47"
   },
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "f35a7213fc9a7e80a7c210d11b3a8094d3a8e07e"
   },
   "outputs": [],
   "source": [
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            known_words[word] = embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        except:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "cbf1970d63ea82cc32817b6d2e5f2b976276a08f"
   },
   "outputs": [],
   "source": [
    "vocab_train = build_vocab(train['text'])\n",
    "vocab_test = build_vocab(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "42c2b82740ac82f5678a46b7c82b5525616c1304",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 28.26% of vocab\n",
      "Found embeddings for  83.07% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_train, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 32.97% of vocab\n",
      "Found embeddings for  85.72% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_test, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "c657fb61a5942ee9807258364be3a2d1058471e6"
   },
   "outputs": [],
   "source": [
    "train['lowered_question'] = train['text'].apply(lambda x: x.lower())\n",
    "test['lowered_question'] = test['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a3c70ee2f7670eb6278a855130e5d2426238f590"
   },
   "outputs": [],
   "source": [
    "vocab_train_low = build_vocab(train['lowered_question'])\n",
    "vocab_test_low = build_vocab(test['lowered_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "6e4f5244153ac68b38213a36c3434b3c3a2a2441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 26.54% of vocab\n",
      "Found embeddings for  82.97% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_train_low, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 31.37% of vocab\n",
      "Found embeddings for  85.63% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_test_low, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "7703322c717121d6f8ee06ab7316232c75448ebe"
   },
   "outputs": [],
   "source": [
    "def add_lower(embedding, vocab):\n",
    "    count = 0\n",
    "    for word in vocab:\n",
    "        if word in embedding and word.lower() not in embedding:  \n",
    "            embedding[word.lower()] = embedding[word]\n",
    "            count += 1\n",
    "    print(f\"Added {count} words to embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "77757cf80eeda36376dca64737c61d3100c1acf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Added 502 words to embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "add_lower(embed_glove, vocab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Added 187 words to embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "add_lower(embed_glove, vocab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "1dec1b447767d99aa4814378b85365202e6bc230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 26.99% of vocab\n",
      "Found embeddings for  83.10% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_train_low, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 31.86% of vocab\n",
      "Found embeddings for  85.75% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_test_low, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "70f766c527f6b7d87a0213306d20db49a5cc014f"
   },
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "c95828228f2b28c55a02890c5a882037cad18262"
   },
   "outputs": [],
   "source": [
    "def unknown_punct(embed, punct):\n",
    "    unknown = ''\n",
    "    for p in punct:\n",
    "        if p not in embed:\n",
    "            unknown += p\n",
    "            unknown += ' '\n",
    "    return unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "69129cad1f08fda5912051d273db012f9adb081a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove :\n",
      "“ ” ’ ∞ θ ÷ α • à − β ∅ ³ π ‘ ₹ ´ ° £ € × ™ √ ² — – \n"
     ]
    }
   ],
   "source": [
    "print(\"Glove :\")\n",
    "print(unknown_punct(embed_glove, punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "2ebe824ff42bc0f93aca2884b430cc96c12857b8"
   },
   "outputs": [],
   "source": [
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "a3825a0af80d6443e6e2665edadf2c394d8c92ff"
   },
   "outputs": [],
   "source": [
    "def clean_special_chars(text, punct, mapping):\n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  # Other special characters that I have to deal with in last\n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "b47c945e6f02c2a9f72aedd72da4681695cb20dd"
   },
   "outputs": [],
   "source": [
    "train['lowered_question'] = train['lowered_question'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))\n",
    "test['lowered_question'] = test['lowered_question'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "1d89484c4cd04be56e6d81ea6b2b9ded41371ef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 91.64% of vocab\n",
      "Found embeddings for  99.74% of all text\n"
     ]
    }
   ],
   "source": [
    "vocab_train = build_vocab(train['lowered_question'])\n",
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_train, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 92.49% of vocab\n",
      "Found embeddings for  99.74% of all text\n"
     ]
    }
   ],
   "source": [
    "vocab_test = build_vocab(test['lowered_question'])\n",
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_test, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove special characters and punctuation\n",
    "train['lowered_question'] = train['lowered_question'].replace(r'[^A-Za-z0-9 ]+', '')\n",
    "test['lowered_question'] = test['lowered_question'].replace(r'[^A-Za-z0-9 ]+', '')\n",
    "\n",
    "#remove single letters from text\n",
    "train['lowered_question'] = train['lowered_question'].apply (lambda x: re.sub(r\"((?<=^)|(?<= )).((?=$)|(?= ))\", '', x).strip())\n",
    "test['lowered_question'] = test['lowered_question'].apply (lambda x: re.sub(r\"((?<=^)|(?<= )).((?=$)|(?= ))\", '', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['lowered_question']\n",
    "test['text'] = test['lowered_question']\n",
    "\n",
    "del train['lowered_question']\n",
    "del test['lowered_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_custom(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in custom:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = ['odin', 'mr', 'said']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(remove_custom)\n",
    "test['text'] = test['text'].apply(remove_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_list = []\n",
    "for word in train['text']:\n",
    "    train_word_list.append(word.split(\" \"))\n",
    "train_word_list = [y for x in train_word_list for y in x]\n",
    "\n",
    "test_word_list = []\n",
    "for word in test['text']:\n",
    "    test_word_list.append(word.split(\" \"))\n",
    "test_word_list = [y for x in test_word_list for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(input_list):\n",
    "    word_count = {}\n",
    "    for word in input_list:\n",
    "        if word in  word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = counter(train_word_list)\n",
    "word_count = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "output_train = pd.DataFrame(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = counter(test_word_list)\n",
    "word_count = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "output_test = pd.DataFrame(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'and',\n",
       " 'to',\n",
       " 'of',\n",
       " 'in',\n",
       " 'he',\n",
       " 'you',\n",
       " 'it',\n",
       " 'that',\n",
       " 'was',\n",
       " 'his',\n",
       " 'with',\n",
       " 'had',\n",
       " 'for',\n",
       " 'as',\n",
       " 'not',\n",
       " 'at',\n",
       " 'her',\n",
       " 'but',\n",
       " 'my',\n",
       " 'is',\n",
       " 'have',\n",
       " 'she',\n",
       " 'be',\n",
       " 'me',\n",
       " 'him',\n",
       " 'on',\n",
       " 'all',\n",
       " 'so',\n",
       " 'this',\n",
       " 'what',\n",
       " 'there',\n",
       " 'by',\n",
       " 'from',\n",
       " 'no',\n",
       " 'which',\n",
       " 'were',\n",
       " 'we',\n",
       " 'one',\n",
       " 'they',\n",
       " 'if',\n",
       " 'would',\n",
       " 'been',\n",
       " 'are',\n",
       " 'your',\n",
       " 'an',\n",
       " 'very',\n",
       " 'do',\n",
       " 'when',\n",
       " 'could',\n",
       " 'will',\n",
       " 'out',\n",
       " 'or',\n",
       " 'up',\n",
       " 'man',\n",
       " 'upon',\n",
       " 'them',\n",
       " 'now',\n",
       " 'more',\n",
       " 'who',\n",
       " 'then',\n",
       " 'am',\n",
       " 'some',\n",
       " 'know',\n",
       " 'into',\n",
       " 'well',\n",
       " 'about',\n",
       " 'did',\n",
       " 'time',\n",
       " 'how',\n",
       " 'only',\n",
       " 'little',\n",
       " 'can',\n",
       " 'see',\n",
       " 'their',\n",
       " 'come',\n",
       " 'like',\n",
       " 'before',\n",
       " 'should',\n",
       " 'must',\n",
       " 'here',\n",
       " 'such',\n",
       " 'any',\n",
       " 'good',\n",
       " 'has',\n",
       " 'down',\n",
       " 'than',\n",
       " 'say',\n",
       " 'much',\n",
       " 'think',\n",
       " 'us',\n",
       " 'again',\n",
       " 'never',\n",
       " 'our',\n",
       " 'too',\n",
       " 'cried',\n",
       " 'may',\n",
       " 'sir',\n",
       " 'two',\n",
       " 'go',\n",
       " 'other',\n",
       " 'don',\n",
       " 'over',\n",
       " 'after',\n",
       " 'though',\n",
       " 'nothing',\n",
       " 'made',\n",
       " 'himself',\n",
       " 'old',\n",
       " 'own',\n",
       " 'came',\n",
       " 'great',\n",
       " 'last',\n",
       " 'why',\n",
       " 'way',\n",
       " 'thought',\n",
       " 'might',\n",
       " 'first',\n",
       " 'hand',\n",
       " 'shall',\n",
       " 'back',\n",
       " 'day',\n",
       " 'even',\n",
       " 'long',\n",
       " 'face',\n",
       " 'away',\n",
       " 'mrs',\n",
       " 'room',\n",
       " 'house',\n",
       " 'without',\n",
       " 'every',\n",
       " 'where',\n",
       " 'miss',\n",
       " 'once',\n",
       " 'still',\n",
       " 'eyes',\n",
       " 'looked',\n",
       " 'asked',\n",
       " 'll',\n",
       " 'being',\n",
       " 'these',\n",
       " 'tell',\n",
       " 'went',\n",
       " 'most',\n",
       " 'just',\n",
       " 'make',\n",
       " 'young',\n",
       " 'take',\n",
       " 'quite',\n",
       " 'head',\n",
       " 'something',\n",
       " 'off',\n",
       " 'look',\n",
       " 'yes',\n",
       " 'dear',\n",
       " 'night',\n",
       " 'myself',\n",
       " 'yet',\n",
       " 'let',\n",
       " 'door',\n",
       " 'same',\n",
       " 'another',\n",
       " 'oh',\n",
       " 'ever',\n",
       " 'life',\n",
       " 'mind',\n",
       " 'moment',\n",
       " 'saw',\n",
       " 'prince',\n",
       " 'its',\n",
       " 'heard',\n",
       " 'always',\n",
       " 'father',\n",
       " 'put',\n",
       " 'three',\n",
       " 'took',\n",
       " 'give',\n",
       " 'seemed',\n",
       " 'while',\n",
       " 'left',\n",
       " 'perhaps',\n",
       " 'through',\n",
       " 'looking',\n",
       " 'better',\n",
       " 'began',\n",
       " 'right',\n",
       " 'going',\n",
       " 'get',\n",
       " 'heart',\n",
       " 'done',\n",
       " 'many',\n",
       " 'thing',\n",
       " 'place',\n",
       " 'hands',\n",
       " 'lady',\n",
       " 'word',\n",
       " 'suddenly',\n",
       " 'soon',\n",
       " 'indeed',\n",
       " 'enough',\n",
       " 'told',\n",
       " 'replied',\n",
       " 'found',\n",
       " 'got',\n",
       " 'friend',\n",
       " 've',\n",
       " 'woman',\n",
       " 'those',\n",
       " 'sure',\n",
       " 'turned',\n",
       " 'seen',\n",
       " 'people',\n",
       " 'believe',\n",
       " 'mother',\n",
       " 'knew',\n",
       " 'round',\n",
       " 'side',\n",
       " 'men',\n",
       " 'returned',\n",
       " 'course',\n",
       " 'morning',\n",
       " 'half',\n",
       " 'herself',\n",
       " 'anything',\n",
       " 'love',\n",
       " 'voice',\n",
       " 'under',\n",
       " 'both',\n",
       " 'whole',\n",
       " 'words',\n",
       " 'far',\n",
       " 'almost',\n",
       " 'however',\n",
       " 'sat',\n",
       " 'name',\n",
       " 'want',\n",
       " 'home',\n",
       " 'find',\n",
       " 'felt',\n",
       " 'really',\n",
       " 'whom',\n",
       " 'because',\n",
       " 'rather',\n",
       " 'hear',\n",
       " 'poor',\n",
       " 'having',\n",
       " 'doctor',\n",
       " 'against',\n",
       " 'end',\n",
       " 'stood',\n",
       " 'speak',\n",
       " 'yourself',\n",
       " 'brother',\n",
       " 'answered',\n",
       " 'matter',\n",
       " 'money',\n",
       " 'between',\n",
       " 'gone',\n",
       " 'understand',\n",
       " 'cannot',\n",
       " 'years',\n",
       " 'brought',\n",
       " 'part',\n",
       " 'boy',\n",
       " 'hope',\n",
       " 'gave',\n",
       " 'light',\n",
       " 'together',\n",
       " 'few',\n",
       " 'among',\n",
       " 'mean',\n",
       " 'god',\n",
       " 'open',\n",
       " 'since',\n",
       " 'ye',\n",
       " 'table',\n",
       " 'set',\n",
       " 'gentleman',\n",
       " 'case',\n",
       " 'evening',\n",
       " 'ask',\n",
       " 'already',\n",
       " 'things',\n",
       " 'hour',\n",
       " 'sister',\n",
       " 'lord',\n",
       " 'new',\n",
       " 'leave',\n",
       " 'taken',\n",
       " 'does',\n",
       " 'lay',\n",
       " 'letter',\n",
       " 'next',\n",
       " 'world',\n",
       " 'passed',\n",
       " 'business',\n",
       " 'general',\n",
       " 'master',\n",
       " 'wife',\n",
       " 'least',\n",
       " 'days',\n",
       " 'family',\n",
       " 'certainly',\n",
       " 'question',\n",
       " 'each',\n",
       " 'answer',\n",
       " 'doubt',\n",
       " 'everything',\n",
       " 'nor',\n",
       " 'idea',\n",
       " 'wish',\n",
       " 'else',\n",
       " 'behind',\n",
       " 'keep',\n",
       " 'best',\n",
       " 'remember',\n",
       " 'help',\n",
       " 'towards',\n",
       " 'alone',\n",
       " 'coming',\n",
       " 'whether',\n",
       " 'suppose',\n",
       " 'air',\n",
       " 'sort',\n",
       " 'point',\n",
       " 'until',\n",
       " 'small',\n",
       " 'strange',\n",
       " 'read',\n",
       " 'fellow',\n",
       " 'manner',\n",
       " 'true',\n",
       " 'five',\n",
       " 'work',\n",
       " 'aunt',\n",
       " 'present',\n",
       " 'short',\n",
       " 'won',\n",
       " 'black',\n",
       " 'added',\n",
       " 'child',\n",
       " 'fire',\n",
       " 'town',\n",
       " 'called',\n",
       " 'says',\n",
       " 'less',\n",
       " 'till',\n",
       " 'girl',\n",
       " 'captain',\n",
       " 'window',\n",
       " 'afraid',\n",
       " 'kind',\n",
       " 'happy',\n",
       " 'street',\n",
       " 'talk',\n",
       " 'often',\n",
       " 'walked',\n",
       " 'known',\n",
       " 'spoke',\n",
       " 'dead',\n",
       " 'dark',\n",
       " 'observed',\n",
       " 'friends',\n",
       " 'within',\n",
       " 're',\n",
       " 'fact',\n",
       " 'full',\n",
       " 'chair',\n",
       " 'ah',\n",
       " 'ill',\n",
       " 'either',\n",
       " 'bed',\n",
       " 'four',\n",
       " 'reason',\n",
       " 'possible',\n",
       " 'near',\n",
       " 'hardly',\n",
       " 'fell',\n",
       " 'call',\n",
       " 'feel',\n",
       " 'given',\n",
       " 'used',\n",
       " 'death',\n",
       " 'person',\n",
       " 'times',\n",
       " 'white',\n",
       " 'ready',\n",
       " 'certain',\n",
       " 'ran',\n",
       " 'silence',\n",
       " 'kept',\n",
       " 'smile',\n",
       " 'high',\n",
       " 'struck',\n",
       " 'clear',\n",
       " 'rest',\n",
       " 'country',\n",
       " 'others',\n",
       " 'taking',\n",
       " 'strong',\n",
       " 'sometimes',\n",
       " 'hard',\n",
       " 'feet',\n",
       " 'lost',\n",
       " 'didn',\n",
       " 'mine',\n",
       " 'appeared',\n",
       " 'thousand',\n",
       " 'also',\n",
       " 'turn',\n",
       " 'second',\n",
       " 'large',\n",
       " 'glad',\n",
       " 'pleasure',\n",
       " 'hundred',\n",
       " 'making',\n",
       " 'hold',\n",
       " 'afterwards',\n",
       " 'means',\n",
       " 'ten',\n",
       " 'wanted',\n",
       " 'subject',\n",
       " 'feeling',\n",
       " 'opened',\n",
       " 'along',\n",
       " 'followed',\n",
       " 'continued',\n",
       " 'doing',\n",
       " 'deal',\n",
       " 'water',\n",
       " 'held',\n",
       " 'london',\n",
       " 'bring',\n",
       " 'show',\n",
       " 'above',\n",
       " 'son',\n",
       " 'saying',\n",
       " 'sitting',\n",
       " 'gentlemen',\n",
       " 'fear',\n",
       " 'joe',\n",
       " 'met',\n",
       " 'pretty',\n",
       " 'eye',\n",
       " 'truth',\n",
       " 'state',\n",
       " 'company',\n",
       " 'minutes',\n",
       " 'need',\n",
       " 'cold',\n",
       " 'across',\n",
       " 'forward',\n",
       " 'thinking',\n",
       " 'arm',\n",
       " 'corner',\n",
       " 'care',\n",
       " 'run',\n",
       " 'low',\n",
       " 'body',\n",
       " 'walk',\n",
       " 'silent',\n",
       " 'close',\n",
       " 'ivan',\n",
       " 'nature',\n",
       " 'children',\n",
       " 'able',\n",
       " 'sent',\n",
       " 'arms',\n",
       " 'laughed',\n",
       " 'turning',\n",
       " 'late',\n",
       " 'past',\n",
       " 'use',\n",
       " 'account',\n",
       " 'interest',\n",
       " 'husband',\n",
       " 'happened',\n",
       " 'live',\n",
       " 'ought',\n",
       " 'became',\n",
       " 'story',\n",
       " 'sit',\n",
       " 'instant',\n",
       " 'twenty',\n",
       " 'return',\n",
       " 'red',\n",
       " 'standing',\n",
       " 'whose',\n",
       " 'paper',\n",
       " 'sight',\n",
       " 'blood',\n",
       " 'talking',\n",
       " 'bad',\n",
       " 'repeated',\n",
       " 'opinion',\n",
       " 'dare',\n",
       " 'ground',\n",
       " 'seeing',\n",
       " 'ago',\n",
       " 'character',\n",
       " 'feelings',\n",
       " 'object',\n",
       " 'simply',\n",
       " 'sound',\n",
       " 'clock',\n",
       " 'please',\n",
       " 'laughing',\n",
       " 'attention',\n",
       " 'minute',\n",
       " 'surprise',\n",
       " 'therefore',\n",
       " 'tried',\n",
       " 'daughter',\n",
       " 'stopped',\n",
       " 'none',\n",
       " 'thank',\n",
       " 'beyond',\n",
       " 'visit',\n",
       " 'knows',\n",
       " 'different',\n",
       " 'odins',\n",
       " 'change',\n",
       " 'hair',\n",
       " 'year',\n",
       " 'hours',\n",
       " 'party',\n",
       " 'creature',\n",
       " 'speaking',\n",
       " 'drew',\n",
       " 'soul',\n",
       " 'several',\n",
       " 'bear',\n",
       " 'stand',\n",
       " 'immediately',\n",
       " 'sorry',\n",
       " 'deep',\n",
       " 'conversation',\n",
       " 'expression',\n",
       " 'impossible',\n",
       " 'stay',\n",
       " 'wonder',\n",
       " 'secret',\n",
       " 'neither',\n",
       " 'laid',\n",
       " 'road',\n",
       " 'six',\n",
       " 'yesterday',\n",
       " 'sudden',\n",
       " 'jane',\n",
       " 'received',\n",
       " 'themselves',\n",
       " 'appearance',\n",
       " 'longer',\n",
       " 'note',\n",
       " 'sense',\n",
       " 'carried',\n",
       " 'pass',\n",
       " 'besides',\n",
       " 'lips',\n",
       " 'fine',\n",
       " 'carriage',\n",
       " 'waiting',\n",
       " 'married',\n",
       " 'angry',\n",
       " 'sea',\n",
       " 'power',\n",
       " 'purpose',\n",
       " 'wait',\n",
       " 'honour',\n",
       " 'front',\n",
       " 'seems',\n",
       " 'entered',\n",
       " 'tears',\n",
       " 'week',\n",
       " 'order',\n",
       " 'beside',\n",
       " 'led',\n",
       " 'ha',\n",
       " 'dinner',\n",
       " 'companion',\n",
       " 'perfectly',\n",
       " 'forth',\n",
       " 'uncle',\n",
       " 'seem',\n",
       " 'quiet',\n",
       " 'likely',\n",
       " 'common',\n",
       " 'straight',\n",
       " 'during',\n",
       " 'morrow',\n",
       " 'early',\n",
       " 'step',\n",
       " 'sake',\n",
       " 'laugh',\n",
       " 'later',\n",
       " 'glass',\n",
       " 'exactly',\n",
       " 'write',\n",
       " 'fancy',\n",
       " 'wrong',\n",
       " 'lying',\n",
       " 'horse',\n",
       " 'cut',\n",
       " 'getting',\n",
       " 'meant',\n",
       " 'foot',\n",
       " 'broke',\n",
       " 'wall',\n",
       " 'surprised',\n",
       " 'dr',\n",
       " 'book',\n",
       " 'showed',\n",
       " 'wind',\n",
       " 'reached',\n",
       " 'acquaintance',\n",
       " 'thoughts',\n",
       " 'spirits',\n",
       " 'broken',\n",
       " 'usual',\n",
       " 'save',\n",
       " 'police',\n",
       " 'spirit',\n",
       " 'garden',\n",
       " 'pale',\n",
       " 'itself',\n",
       " 'imagine',\n",
       " 'meet',\n",
       " 'comes',\n",
       " 'become',\n",
       " 'earth',\n",
       " 'expected',\n",
       " 'spite',\n",
       " 'dora',\n",
       " 'walking',\n",
       " 'position',\n",
       " 'ladies',\n",
       " 'heavy',\n",
       " 'assure',\n",
       " 'raised',\n",
       " 'pleased',\n",
       " 'remained',\n",
       " 'cry',\n",
       " 'floor',\n",
       " 'entirely',\n",
       " 'talked',\n",
       " 'happiness',\n",
       " 'stepan',\n",
       " 'living',\n",
       " 'women',\n",
       " 'trouble',\n",
       " 'months',\n",
       " 'forgive',\n",
       " 'particular',\n",
       " 'shook',\n",
       " 'cause',\n",
       " 'whatever',\n",
       " 'caught',\n",
       " 'heaven',\n",
       " 'chance',\n",
       " 'listen',\n",
       " 'wished',\n",
       " 'box',\n",
       " 'surely',\n",
       " 'try',\n",
       " 'pray',\n",
       " 'anxious',\n",
       " 'beginning',\n",
       " 'worth',\n",
       " 'thus',\n",
       " 'wine',\n",
       " 'moved',\n",
       " 'tone',\n",
       " 'real',\n",
       " 'society',\n",
       " 'latter',\n",
       " 'inquired',\n",
       " 'natural',\n",
       " 'murder',\n",
       " 'fair',\n",
       " 'marriage',\n",
       " 'begin',\n",
       " 'circumstances',\n",
       " 'shoulder',\n",
       " 'remarked',\n",
       " 'figure',\n",
       " 'danger',\n",
       " 'occasion',\n",
       " 'notice',\n",
       " 'lived',\n",
       " 'allow',\n",
       " 'probably',\n",
       " 'madame',\n",
       " 'sleep',\n",
       " 'worse',\n",
       " 'seven',\n",
       " 'nay',\n",
       " 'directly',\n",
       " 'except',\n",
       " 'steps',\n",
       " 'die',\n",
       " 'line',\n",
       " 'obliged',\n",
       " 'exclaimed',\n",
       " 'running',\n",
       " 'send',\n",
       " 'loved',\n",
       " 'watch',\n",
       " 'giving',\n",
       " 'although',\n",
       " 'drawing',\n",
       " 'further',\n",
       " 'died',\n",
       " 'em',\n",
       " 'slowly',\n",
       " 'lie',\n",
       " 'mouth',\n",
       " 'service',\n",
       " 'roubles',\n",
       " 'length',\n",
       " 'court',\n",
       " 'hat',\n",
       " 'whispered',\n",
       " 'respect',\n",
       " 'wouldn',\n",
       " 'fortune',\n",
       " 'fall',\n",
       " 'yours',\n",
       " 'office',\n",
       " 'stone',\n",
       " 'serious',\n",
       " 'listened',\n",
       " 'particularly',\n",
       " 'direction',\n",
       " 'anne',\n",
       " 'written',\n",
       " 'knowledge',\n",
       " 'arrived',\n",
       " 'play',\n",
       " 'muttered',\n",
       " 'forgotten',\n",
       " 'passage',\n",
       " 'public',\n",
       " 'trust',\n",
       " 'extraordinary',\n",
       " 'self',\n",
       " 'news',\n",
       " 'drink',\n",
       " 'settled',\n",
       " 'quickly',\n",
       " 'trying',\n",
       " 'comfort',\n",
       " 'anyone',\n",
       " 'forget',\n",
       " 'stop',\n",
       " 'smiling',\n",
       " 'papers',\n",
       " 'cross',\n",
       " 'reply',\n",
       " 'follow',\n",
       " 'distance',\n",
       " 'marry',\n",
       " 'easy',\n",
       " 'especially',\n",
       " 'necessary',\n",
       " 'burst',\n",
       " 'effect',\n",
       " 'stairs',\n",
       " 'absolutely',\n",
       " 'coat',\n",
       " 'gate',\n",
       " 'silver',\n",
       " 'convinced',\n",
       " 'terrible',\n",
       " 'wild',\n",
       " 'view',\n",
       " 'tea',\n",
       " 'pay',\n",
       " 'quick',\n",
       " 'third',\n",
       " 'consider',\n",
       " 'believed',\n",
       " 'seat',\n",
       " 'church',\n",
       " 'bit',\n",
       " 'meeting',\n",
       " 'ashamed',\n",
       " 'breath',\n",
       " 'curiosity',\n",
       " 'nobody',\n",
       " 'hall',\n",
       " 'servant',\n",
       " 'knowing',\n",
       " 'engaged',\n",
       " 'devil',\n",
       " 'determined',\n",
       " 'prisoner',\n",
       " 'situation',\n",
       " 'leaving',\n",
       " 'smiled',\n",
       " 'age',\n",
       " 'duty',\n",
       " 'closed',\n",
       " 'top',\n",
       " 'excuse',\n",
       " 'instantly',\n",
       " 'changed',\n",
       " 'ma',\n",
       " 'bound',\n",
       " 'nonsense',\n",
       " 'shaking',\n",
       " 'scarcely',\n",
       " 'letters',\n",
       " 'evidently',\n",
       " 'judge',\n",
       " 'madam',\n",
       " 'law',\n",
       " 'shouted',\n",
       " 'sun',\n",
       " 'fodin',\n",
       " 'beg',\n",
       " 'supposed',\n",
       " 'future',\n",
       " 'aware',\n",
       " 'dress',\n",
       " 'instead',\n",
       " 'started',\n",
       " 'fit',\n",
       " 'nearly',\n",
       " 'wood',\n",
       " 'ship',\n",
       " 'beautiful',\n",
       " 'expect',\n",
       " 'jew',\n",
       " 'spoken',\n",
       " 'couldn',\n",
       " 'english',\n",
       " 'fool',\n",
       " 'free',\n",
       " 'england',\n",
       " 'scene',\n",
       " 'clothes',\n",
       " 'twice',\n",
       " 'plain',\n",
       " 'pleasant',\n",
       " 'shut',\n",
       " 'desire',\n",
       " 'piece',\n",
       " 'looks',\n",
       " 'agreeable',\n",
       " 'dog',\n",
       " 'presence',\n",
       " 'excellent',\n",
       " 'questions',\n",
       " 'fixed',\n",
       " 'confidence',\n",
       " 'understood',\n",
       " 'grew',\n",
       " 'glance',\n",
       " 'fresh',\n",
       " 'pulled',\n",
       " 'dropped',\n",
       " 'shot',\n",
       " 'green',\n",
       " 'threw',\n",
       " 'human',\n",
       " 'evidence',\n",
       " 'frightened',\n",
       " 'sign',\n",
       " 'affection',\n",
       " 'carry',\n",
       " 'mad',\n",
       " 'somewhat',\n",
       " 'contrary',\n",
       " 'outside',\n",
       " 'windows',\n",
       " 'train',\n",
       " 'single',\n",
       " 'safe',\n",
       " 'horses',\n",
       " 'reading',\n",
       " 'former',\n",
       " 'rooms',\n",
       " 'evil',\n",
       " 'paid',\n",
       " 'difficult',\n",
       " 'bright',\n",
       " 'grave',\n",
       " 'dreadful',\n",
       " 'greater',\n",
       " 'appear',\n",
       " 'strength',\n",
       " 'remembered',\n",
       " 'quarter',\n",
       " 'stranger',\n",
       " 'observe',\n",
       " 'dressed',\n",
       " 'candle',\n",
       " 'form',\n",
       " 'sofa',\n",
       " 'boys',\n",
       " 'delighted',\n",
       " 'spot',\n",
       " 'satisfaction',\n",
       " 'trees',\n",
       " 'farther',\n",
       " 'ourselves',\n",
       " 'private',\n",
       " 'pip',\n",
       " 'miles',\n",
       " 'speech',\n",
       " 'pride',\n",
       " 'horror',\n",
       " 'bell',\n",
       " 'tall',\n",
       " 'number',\n",
       " 'someone',\n",
       " 'ears',\n",
       " 'easily',\n",
       " 'handsome',\n",
       " 'countenance',\n",
       " 'journey',\n",
       " 'blue',\n",
       " 'influence',\n",
       " 'tongue',\n",
       " 'mention',\n",
       " 'drawn',\n",
       " 'shoulders',\n",
       " 'occurred',\n",
       " 'pity',\n",
       " 'hot',\n",
       " 'facts',\n",
       " 'important',\n",
       " 'offer',\n",
       " 'touch',\n",
       " 'terror',\n",
       " 'beauty',\n",
       " 'complete',\n",
       " 'meaning',\n",
       " 'king',\n",
       " 'eight',\n",
       " 'fond',\n",
       " 'crime',\n",
       " 'promise',\n",
       " 'break',\n",
       " 'spent',\n",
       " 'sharp',\n",
       " 'curious',\n",
       " 'mere',\n",
       " 'satisfied',\n",
       " 'altogether',\n",
       " 'considered',\n",
       " 'presently',\n",
       " 'proud',\n",
       " 'faces',\n",
       " 'waited',\n",
       " 'decided',\n",
       " 'finger',\n",
       " 'hoped',\n",
       " 'fingers',\n",
       " 'hurried',\n",
       " 'crowd',\n",
       " 'extremely',\n",
       " 'begun',\n",
       " 'st',\n",
       " 'writing',\n",
       " 'lad',\n",
       " 'mentioned',\n",
       " 'thrown',\n",
       " 'breakfast',\n",
       " 'pain',\n",
       " 'knees',\n",
       " 'merely',\n",
       " 'makes',\n",
       " 'possibly',\n",
       " 'address',\n",
       " 'nearer',\n",
       " 'hill',\n",
       " 'quietly',\n",
       " 'pause',\n",
       " 'putting',\n",
       " 'joy',\n",
       " 'anger',\n",
       " 'darkness',\n",
       " 'trembling',\n",
       " 'explain',\n",
       " 'telling',\n",
       " 'explanation',\n",
       " 'unhappy',\n",
       " 'confess',\n",
       " 'rushed',\n",
       " 'kindness',\n",
       " 'bow',\n",
       " 'drunk',\n",
       " 'act',\n",
       " 'middle',\n",
       " 'interrupted',\n",
       " 'keeping',\n",
       " 'explained',\n",
       " 'wrote',\n",
       " 'knight',\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlapping_words = []\n",
    "for a in range(output_train.shape[0]):\n",
    "    if output_train[0][a] in list(output_test[0]):\n",
    "        overlapping_words.append(output_train[0][a])\n",
    "overlapping_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique = []\n",
    "for txt in output_train[0]:\n",
    "    if txt in overlapping_words:\n",
    "        pass\n",
    "    else:\n",
    "        train_unique.append(txt)\n",
    "\n",
    "test_unique = []\n",
    "for txt in output_test[0]:\n",
    "    if txt in overlapping_words:\n",
    "        pass\n",
    "    else:\n",
    "        test_unique.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique = pd.Series(train_unique)\n",
    "train_unique.to_csv('train_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unique = pd.Series(test_unique)\n",
    "test_unique.to_csv('test_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
