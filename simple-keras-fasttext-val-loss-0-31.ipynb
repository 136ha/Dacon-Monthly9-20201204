{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "93e00783-a024-4e87-a5e1-6709cb8cc981",
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "b05ef71268db76a4e2565177bf6a5668a5fc428e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, Embedding, GRU, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "a5cc2c3e-7960-482e-b548-c447b89925ec",
    "_uuid": "d700f739101e37903112e1de293323dcfbb577be"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "a2c = {0:0, 1:1, 2:2, 3:3, 4:4}\n",
    "y = np.array([a2c[a] for a in df.author])\n",
    "# y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "c1d00b0d-90e0-4f19-842c-51a82de42a10",
    "_kg_hide-output": true,
    "_uuid": "246a428ca3a063294c15c8c08d234ecf01e4ddbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c 0   1   2   3   4   \n",
      "é 2 1 20 90 45 \n",
      "* 15 0 45 20 187 \n",
      "Œ 0 0 0 1 0 \n",
      "s 120860 107436 115014 152460 79389 \n",
      "H 3079 2404 3269 4943 2114 \n",
      "N 1573 833 1451 1437 774 \n",
      "’ 9929 673 2829 9763 2946 \n",
      ": 919 505 255 734 448 \n",
      "{ 0 0 1 0 11 \n",
      "/ 1 0 0 0 0 \n",
      "ä 0 0 0 2 2 \n",
      "p 32466 26918 28574 39069 20782 \n",
      "7 3 4 52 5 18 \n",
      "j 1445 1798 1454 2353 831 \n",
      "1 5 26 143 27 37 \n",
      "Ê 0 0 0 0 1 \n",
      "D 2068 573 1074 1187 821 \n",
      "i 136740 120325 122259 172110 83899 \n",
      "9 2 5 28 4 4 \n",
      "ñ 0 2 0 0 0 \n",
      "L 896 1109 1293 936 573 \n",
      "g 41074 33639 35580 50346 24317 \n",
      "v 17667 19267 18986 26328 11072 \n",
      "! 4532 2084 2153 6118 1829 \n",
      "‐ 0 0 0 769 0 \n",
      "A 2994 1997 3159 4508 2809 \n",
      "x 2564 2753 2567 3839 1292 \n",
      ") 518 154 86 455 279 \n",
      "q 1987 2113 1690 2559 1051 \n",
      "” 4950 5069 9669 10387 5222 \n",
      ", 50046 32401 32897 51600 29055 \n",
      "— 662 246 727 706 574 \n",
      "ï 0 0 0 67 1 \n",
      "' 9623 2454 1925 4138 3448 \n",
      "u 57950 51391 57526 82101 39046 \n",
      "n 146493 131051 129620 187149 93382 \n",
      "\" 1148 3153 2728 7927 3077 \n",
      "5 0 5 42 5 12 \n",
      "_ 648 1756 452 1800 314 \n",
      "S 2393 2426 3073 3205 1748 \n",
      "[ 9 16 4 12 0 \n",
      "º 0 0 4 0 0 \n",
      "U 405 172 132 119 135 \n",
      "P 993 527 1059 1091 811 \n",
      "£ 0 1 27 0 0 \n",
      "V 138 105 249 343 104 \n",
      "W 3134 1559 3244 4036 1558 \n",
      "ù 0 0 0 0 1 \n",
      "X 17 1 8 15 6 \n",
      "æ 0 0 11 12 4 \n",
      "# 0 0 0 0 2 \n",
      ". 26744 20437 26911 42676 16674 \n",
      "] 1 16 4 11 0 \n",
      "k 17941 10625 15114 20913 10905 \n",
      "f 41845 39002 40328 51760 28119 \n",
      "I 17203 9264 14668 18437 10104 \n",
      "Æ 0 0 0 4 0 \n",
      "O 1439 717 1041 1586 772 \n",
      "h 126189 106275 125038 158314 83513 \n",
      "ç 0 0 0 8 2 \n",
      "0 0 15 90 8 9 \n",
      "Y 1640 1243 1715 2742 937 \n",
      "m 52347 42155 47070 65266 32487 \n",
      "c 42773 40070 45526 54244 28066 \n",
      "ê 1 6 2 47 3 \n",
      "a 161699 132986 152850 199943 106737 \n",
      "z 487 484 875 1136 453 \n",
      "œ 0 0 4 4 1 \n",
      "d 103482 82917 87785 124850 67904 \n",
      "o 164844 144734 150144 212942 103291 \n",
      "2 5 24 72 11 12 \n",
      "4 1 7 58 7 13 \n",
      "e 244384 218441 232028 312141 163509 \n",
      "â 0 0 2 0 9 \n",
      "? 3932 1885 3526 6750 2142 \n",
      "î 0 0 1 2 1 \n",
      "b 28044 25450 25733 33631 18775 \n",
      "l 75785 65345 72356 102716 52572 \n",
      "R 543 290 453 611 551 \n",
      "K 102 42 198 297 136 \n",
      "J 1269 424 400 192 240 \n",
      "ì 0 0 0 0 1 \n",
      "ü 0 0 1 54 1 \n",
      "8 0 9 74 16 5 \n",
      "; 4893 5611 867 3566 5270 \n",
      "ë 0 0 0 1 0 \n",
      "} 0 0 1 0 11 \n",
      "y 43130 37729 38450 60049 27695 \n",
      "E 1019 638 989 741 638 \n",
      "G 758 281 789 1140 680 \n",
      "“ 5064 5152 10671 10697 5235 \n",
      "t 175725 149271 166115 230690 112743 \n",
      "B 1849 1405 2243 2696 1427 \n",
      "è 0 1 3 43 6 \n",
      "r 114553 103044 109640 134840 75525 \n",
      "M 6447 5105 2593 1384 1778 \n",
      "F 638 326 916 969 659 \n",
      "ô 0 0 4 7 2 \n",
      "C 1539 775 1290 770 836 \n",
      "Q 84 17 75 70 27 \n",
      "& 3 8 13 0 0 \n",
      "ö 1 0 0 1 0 \n",
      "( 510 154 86 455 279 \n",
      "Z 1 2 24 162 6 \n",
      "- 7738 7633 4409 6466 3029 \n",
      "‘ 5545 64 1015 888 1495 \n",
      "3 1 13 57 4 5 \n",
      "6 1 10 38 5 9 \n",
      "T 4689 3108 5177 5918 3212 \n",
      "à 0 3 2 33 2 \n",
      "w 48074 39295 47339 56793 30952 \n"
     ]
    }
   ],
   "source": [
    "counter = {name : defaultdict(int) for name in set(df.author)}\n",
    "for (text, author) in zip(df.text, df.author):\n",
    "    text = text.replace(' ', '')\n",
    "    for c in text:\n",
    "        counter[author][c] += 1\n",
    "\n",
    "chars = set()\n",
    "for v in counter.values():\n",
    "    chars |= v.keys()\n",
    "    \n",
    "names = [author for author in counter.keys()]\n",
    "\n",
    "print('c ', end='')\n",
    "for n in names:\n",
    "    print(n, end='   ')\n",
    "print()\n",
    "for c in chars:    \n",
    "    print(c, end=' ')\n",
    "    for n in names:\n",
    "        print(counter[n][c], end=' ')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "72ff2ff5-0945-4f39-8b02-39e4d5df16c5",
    "_uuid": "999012010cd8b9b20d3c5b16c11a2374a5ce44c0"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace(\"' \", \" ' \")\n",
    "    signs = set(',.:;\"?!')\n",
    "    prods = set(text) & signs\n",
    "    if not prods:\n",
    "        return text\n",
    "\n",
    "    for sign in prods:\n",
    "        text = text.replace(sign, ' {} '.format(sign) )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "f123742f-540f-438d-aba3-ebbca69235be",
    "_uuid": "53f325a090a44f7109f0537022398797704cdc80"
   },
   "outputs": [],
   "source": [
    "def create_docs(df, n_gram_max=2):\n",
    "    def add_ngram(q, n_gram_max):\n",
    "            ngrams = []\n",
    "            for n in range(2, n_gram_max+1):\n",
    "                for w_index in range(len(q)-n+1):\n",
    "                    ngrams.append('--'.join(q[w_index:w_index+n]))\n",
    "            return q + ngrams\n",
    "        \n",
    "    docs = []\n",
    "    for doc in df.text:\n",
    "        doc = preprocess(doc).split()\n",
    "        docs.append(' '.join(add_ngram(doc, n_gram_max)))\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "888047de-806e-4ad2-9fff-18b4d6583d30",
    "_uuid": "150f9f6643e6753386b2021ac812ecc0cac66202"
   },
   "outputs": [],
   "source": [
    "min_count = 2\n",
    "\n",
    "docs = create_docs(df)\n",
    "tokenizer = Tokenizer(lower=False, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=False, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "docs = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "maxlen = 256\n",
    "\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "393d1ddb-0a87-42a3-8575-53ff7abff1da",
    "_uuid": "bba1d1a6416876e74ed688f56e4d5bc4990ec12a"
   },
   "outputs": [],
   "source": [
    "input_dim = np.max(docs) + 1\n",
    "embedding_dims = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "2e3e1e3e-22f4-4727-ba6c-67f7b3e80d2f",
    "_uuid": "e6c16572e6b32923af39dfd29467e32b52561bb1"
   },
   "outputs": [],
   "source": [
    "def create_model(embedding_dims=20, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "0db889db-0b3e-4025-8847-e3eb5f853f37",
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "22e57e010206a3044adf7b82160c7c3ca78030f8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "es = EarlyStopping(patience=2, monitor='val_loss')\n",
    "mc = ModelCheckpoint(filepath='fasttext.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = create_docs(df)\n",
    "tokenizer = Tokenizer(lower=True, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=True, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "docs = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "maxlen = 256\n",
    "\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)\n",
    "\n",
    "input_dim = np.max(docs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_x.csv\")\n",
    "docs_test = create_docs(test_df)\n",
    "docs_test = tokenizer.texts_to_sequences(docs_test)\n",
    "docs_test = pad_sequences(sequences=docs_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV started\n",
      "Epoch 1/15\n",
      "1372/1372 [==============================] - 143s 104ms/step - loss: 1.5078 - accuracy: 0.3673 - val_loss: 1.3990 - val_accuracy: 0.5054\n",
      "Epoch 2/15\n",
      "1372/1372 [==============================] - 139s 101ms/step - loss: 1.2147 - accuracy: 0.5854 - val_loss: 1.0914 - val_accuracy: 0.6142\n",
      "Epoch 3/15\n",
      "1372/1372 [==============================] - 129s 94ms/step - loss: 0.9325 - accuracy: 0.6949 - val_loss: 0.9006 - val_accuracy: 0.7003\n",
      "Epoch 4/15\n",
      "1372/1372 [==============================] - 129s 94ms/step - loss: 0.7509 - accuracy: 0.7622 - val_loss: 0.7834 - val_accuracy: 0.7306\n",
      "Epoch 5/15\n",
      "1372/1372 [==============================] - 130s 95ms/step - loss: 0.6229 - accuracy: 0.8066 - val_loss: 0.6998 - val_accuracy: 0.7672\n",
      "Epoch 6/15\n",
      "1372/1372 [==============================] - 112s 81ms/step - loss: 0.5248 - accuracy: 0.8414 - val_loss: 0.6457 - val_accuracy: 0.7873\n",
      "Epoch 7/15\n",
      "1372/1372 [==============================] - 71s 52ms/step - loss: 0.4465 - accuracy: 0.8683 - val_loss: 0.5981 - val_accuracy: 0.7984\n",
      "Epoch 8/15\n",
      "1372/1372 [==============================] - 74s 54ms/step - loss: 0.3823 - accuracy: 0.8903 - val_loss: 0.5662 - val_accuracy: 0.8025\n",
      "Epoch 9/15\n",
      "1372/1372 [==============================] - 74s 54ms/step - loss: 0.3292 - accuracy: 0.9071 - val_loss: 0.5368 - val_accuracy: 0.8174\n",
      "Epoch 10/15\n",
      "1372/1372 [==============================] - 75s 55ms/step - loss: 0.2847 - accuracy: 0.9224 - val_loss: 0.5193 - val_accuracy: 0.8233\n",
      "Epoch 11/15\n",
      "1372/1372 [==============================] - 74s 54ms/step - loss: 0.2474 - accuracy: 0.9338 - val_loss: 0.5039 - val_accuracy: 0.8257\n",
      "Epoch 12/15\n",
      "1372/1372 [==============================] - 74s 54ms/step - loss: 0.2157 - accuracy: 0.9433 - val_loss: 0.4950 - val_accuracy: 0.8260\n",
      "Epoch 13/15\n",
      "1372/1372 [==============================] - 74s 54ms/step - loss: 0.1884 - accuracy: 0.9516 - val_loss: 0.4901 - val_accuracy: 0.8300\n",
      "Epoch 14/15\n",
      "1372/1372 [==============================] - 74s 54ms/step - loss: 0.1651 - accuracy: 0.9584 - val_loss: 0.4833 - val_accuracy: 0.8336\n",
      "Epoch 15/15\n",
      "1372/1372 [==============================] - 74s 54ms/step - loss: 0.1445 - accuracy: 0.9648 - val_loss: 0.4804 - val_accuracy: 0.8326\n",
      "WARNING:tensorflow:From <ipython-input-22-b3127d3f8e1b>:23: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      ".Epoch 1/15\n",
      "1372/1372 [==============================] - 74s 54ms/step - loss: 1.4971 - accuracy: 0.3819 - val_loss: 1.3636 - val_accuracy: 0.5059\n",
      "Epoch 2/15\n",
      "1372/1372 [==============================] - 76s 55ms/step - loss: 1.1841 - accuracy: 0.5977 - val_loss: 1.0551 - val_accuracy: 0.6491\n",
      "Epoch 3/15\n",
      "1372/1372 [==============================] - 76s 56ms/step - loss: 0.9116 - accuracy: 0.7033 - val_loss: 0.8739 - val_accuracy: 0.7177\n",
      "Epoch 4/15\n",
      "1372/1372 [==============================] - 125s 91ms/step - loss: 0.7364 - accuracy: 0.7688 - val_loss: 0.7576 - val_accuracy: 0.7529\n",
      "Epoch 5/15\n",
      "1372/1372 [==============================] - 149s 109ms/step - loss: 0.6119 - accuracy: 0.8120 - val_loss: 0.6773 - val_accuracy: 0.7754\n",
      "Epoch 6/15\n",
      "1372/1372 [==============================] - 144s 105ms/step - loss: 0.5165 - accuracy: 0.8449 - val_loss: 0.6211 - val_accuracy: 0.7960\n",
      "Epoch 7/15\n",
      "1372/1372 [==============================] - 132s 96ms/step - loss: 0.4399 - accuracy: 0.8715 - val_loss: 0.5775 - val_accuracy: 0.8034\n",
      "Epoch 8/15\n",
      "1372/1372 [==============================] - 147s 107ms/step - loss: 0.3776 - accuracy: 0.8925 - val_loss: 0.5509 - val_accuracy: 0.8099\n",
      "Epoch 9/15\n",
      "1372/1372 [==============================] - 148s 108ms/step - loss: 0.3260 - accuracy: 0.9089 - val_loss: 0.5207 - val_accuracy: 0.8241\n",
      "Epoch 10/15\n",
      "1372/1372 [==============================] - 146s 106ms/step - loss: 0.2825 - accuracy: 0.9229 - val_loss: 0.5000 - val_accuracy: 0.8271\n",
      "Epoch 11/15\n",
      "1372/1372 [==============================] - 143s 104ms/step - loss: 0.2453 - accuracy: 0.9357 - val_loss: 0.4859 - val_accuracy: 0.8321\n",
      "Epoch 12/15\n",
      "1372/1372 [==============================] - 137s 100ms/step - loss: 0.2142 - accuracy: 0.9450 - val_loss: 0.4779 - val_accuracy: 0.8354 - loss: 0.2141 - accuracy\n",
      "Epoch 13/15\n",
      "1372/1372 [==============================] - 138s 100ms/step - loss: 0.1876 - accuracy: 0.9528 - val_loss: 0.4688 - val_accuracy: 0.8378\n",
      "Epoch 14/15\n",
      "1372/1372 [==============================] - 142s 103ms/step - loss: 0.1643 - accuracy: 0.9594 - val_loss: 0.4658 - val_accuracy: 0.8397\n",
      "Epoch 15/15\n",
      "1372/1372 [==============================] - 139s 102ms/step - loss: 0.1444 - accuracy: 0.9654 - val_loss: 0.4608 - val_accuracy: 0.8417\n",
      ".Epoch 1/15\n",
      "1372/1372 [==============================] - 142s 103ms/step - loss: 1.4979 - accuracy: 0.3820 - val_loss: 1.3688 - val_accuracy: 0.5266\n",
      "Epoch 2/15\n",
      "1372/1372 [==============================] - 144s 105ms/step - loss: 1.1773 - accuracy: 0.6069 - val_loss: 1.0583 - val_accuracy: 0.6538\n",
      "Epoch 3/15\n",
      "1372/1372 [==============================] - 153s 112ms/step - loss: 0.9034 - accuracy: 0.7077 - val_loss: 0.8776 - val_accuracy: 0.7098\n",
      "Epoch 4/15\n",
      "1372/1372 [==============================] - 158s 115ms/step - loss: 0.7286 - accuracy: 0.7716 - val_loss: 0.7648 - val_accuracy: 0.7356\n",
      "Epoch 5/15\n",
      "1372/1372 [==============================] - 158s 115ms/step - loss: 0.6042 - accuracy: 0.8145 - val_loss: 0.6816 - val_accuracy: 0.7702\n",
      "Epoch 6/15\n",
      "1372/1372 [==============================] - 116s 84ms/step - loss: 0.5092 - accuracy: 0.8471 - val_loss: 0.6241 - val_accuracy: 0.7862\n",
      "Epoch 7/15\n",
      "1372/1372 [==============================] - 75s 54ms/step - loss: 0.4329 - accuracy: 0.8733 - val_loss: 0.5856 - val_accuracy: 0.8001\n",
      "Epoch 8/15\n",
      "1372/1372 [==============================] - 73s 53ms/step - loss: 0.3705 - accuracy: 0.8939 - val_loss: 0.5472 - val_accuracy: 0.8147\n",
      "Epoch 9/15\n",
      "1372/1372 [==============================] - 72s 53ms/step - loss: 0.3192 - accuracy: 0.9103 - val_loss: 0.5221 - val_accuracy: 0.8227\n",
      "Epoch 10/15\n",
      "1372/1372 [==============================] - 72s 53ms/step - loss: 0.2755 - accuracy: 0.9242 - val_loss: 0.5027 - val_accuracy: 0.8257\n",
      "Epoch 11/15\n",
      "1372/1372 [==============================] - 72s 53ms/step - loss: 0.2390 - accuracy: 0.9357 - val_loss: 0.4925 - val_accuracy: 0.8270\n",
      "Epoch 12/15\n",
      "1372/1372 [==============================] - 72s 52ms/step - loss: 0.2080 - accuracy: 0.9457 - val_loss: 0.4814 - val_accuracy: 0.8327\n",
      "Epoch 13/15\n",
      "1372/1372 [==============================] - 72s 52ms/step - loss: 0.1814 - accuracy: 0.9534 - val_loss: 0.4740 - val_accuracy: 0.8360\n",
      "Epoch 14/15\n",
      "1372/1372 [==============================] - 72s 52ms/step - loss: 0.1582 - accuracy: 0.9606 - val_loss: 0.4719 - val_accuracy: 0.8356\n",
      "Epoch 15/15\n",
      "1372/1372 [==============================] - 72s 53ms/step - loss: 0.1384 - accuracy: 0.9664 - val_loss: 0.4674 - val_accuracy: 0.8373\n",
      ".Epoch 1/15\n",
      "1372/1372 [==============================] - 72s 52ms/step - loss: 1.4902 - accuracy: 0.4007 - val_loss: 1.3526 - val_accuracy: 0.5034\n",
      "Epoch 2/15\n",
      "1372/1372 [==============================] - 72s 53ms/step - loss: 1.1705 - accuracy: 0.5991 - val_loss: 1.0533 - val_accuracy: 0.6344\n",
      "Epoch 3/15\n",
      "1372/1372 [==============================] - 72s 52ms/step - loss: 0.9047 - accuracy: 0.7064 - val_loss: 0.8771 - val_accuracy: 0.7005\n",
      "Epoch 4/15\n",
      "1372/1372 [==============================] - 72s 53ms/step - loss: 0.7297 - accuracy: 0.7727 - val_loss: 0.7642 - val_accuracy: 0.7453\n",
      "Epoch 5/15\n",
      "1372/1372 [==============================] - 72s 53ms/step - loss: 0.6042 - accuracy: 0.8171 - val_loss: 0.6840 - val_accuracy: 0.7703\n",
      "Epoch 6/15\n",
      "1372/1372 [==============================] - 72s 52ms/step - loss: 0.5083 - accuracy: 0.8490 - val_loss: 0.6277 - val_accuracy: 0.7888\n",
      "Epoch 7/15\n",
      "1372/1372 [==============================] - 72s 52ms/step - loss: 0.4319 - accuracy: 0.8746 - val_loss: 0.5869 - val_accuracy: 0.8007\n",
      "Epoch 8/15\n",
      "1372/1372 [==============================] - 73s 53ms/step - loss: 0.3697 - accuracy: 0.8951 - val_loss: 0.5544 - val_accuracy: 0.8074\n",
      "Epoch 9/15\n",
      "1372/1372 [==============================] - 72s 52ms/step - loss: 0.3182 - accuracy: 0.9114 - val_loss: 0.5313 - val_accuracy: 0.8127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.2751 - accuracy: 0.9246 - val_loss: 0.5119 - val_accuracy: 0.8228\n",
      "Epoch 11/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.2386 - accuracy: 0.9360 - val_loss: 0.5027 - val_accuracy: 0.8237\n",
      "Epoch 12/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.2077 - accuracy: 0.9455 - val_loss: 0.4927 - val_accuracy: 0.8275\n",
      "Epoch 13/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.1810 - accuracy: 0.9549 - val_loss: 0.4869 - val_accuracy: 0.8307\n",
      "Epoch 14/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.1586 - accuracy: 0.9606 - val_loss: 0.4861 - val_accuracy: 0.8292\n",
      "Epoch 15/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.1391 - accuracy: 0.9666 - val_loss: 0.4810 - val_accuracy: 0.8337\n",
      ".Epoch 1/15\n",
      "1372/1372 [==============================] - 71s 51ms/step - loss: 1.4931 - accuracy: 0.3952 - val_loss: 1.3598 - val_accuracy: 0.5441\n",
      "Epoch 2/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 1.1733 - accuracy: 0.6115 - val_loss: 1.0582 - val_accuracy: 0.6260\n",
      "Epoch 3/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.9036 - accuracy: 0.7093 - val_loss: 0.8773 - val_accuracy: 0.7094\n",
      "Epoch 4/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.7272 - accuracy: 0.7710 - val_loss: 0.7621 - val_accuracy: 0.7451\n",
      "Epoch 5/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.6017 - accuracy: 0.8164 - val_loss: 0.6828 - val_accuracy: 0.7705\n",
      "Epoch 6/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.5066 - accuracy: 0.8492 - val_loss: 0.6264 - val_accuracy: 0.7906\n",
      "Epoch 7/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.4314 - accuracy: 0.8750 - val_loss: 0.5825 - val_accuracy: 0.8026\n",
      "Epoch 8/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.3696 - accuracy: 0.8950 - val_loss: 0.5492 - val_accuracy: 0.8086\n",
      "Epoch 9/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.3185 - accuracy: 0.9113 - val_loss: 0.5258 - val_accuracy: 0.8141\n",
      "Epoch 10/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.2759 - accuracy: 0.9240 - val_loss: 0.5039 - val_accuracy: 0.8251\n",
      "Epoch 11/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.2397 - accuracy: 0.9355 - val_loss: 0.4902 - val_accuracy: 0.8279\n",
      "Epoch 12/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.2085 - accuracy: 0.9468 - val_loss: 0.4799 - val_accuracy: 0.8286\n",
      "Epoch 13/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.1823 - accuracy: 0.9538 - val_loss: 0.4707 - val_accuracy: 0.8333\n",
      "Epoch 14/15\n",
      "1372/1372 [==============================] - 71s 51ms/step - loss: 0.1596 - accuracy: 0.9611 - val_loss: 0.4715 - val_accuracy: 0.8330\n",
      "Epoch 15/15\n",
      "1372/1372 [==============================] - 70s 51ms/step - loss: 0.1402 - accuracy: 0.9663 - val_loss: 0.4695 - val_accuracy: 0.8352\n",
      ".\n",
      "Mean CV LogLoss: 0.472\n"
     ]
    }
   ],
   "source": [
    "cv = 5\n",
    "epochs = 20\n",
    "cv_scores = []\n",
    "pred_test = 0\n",
    "pred_train = np.zeros([docs.shape[0], 5])\n",
    "skf = model_selection.StratifiedKFold(n_splits=cv, shuffle=True, random_state=123)\n",
    "sub_train = pd.DataFrame(columns=[0, 1, 2, 3, 4])\n",
    "sub_train.insert(0, 'index', df.index)\n",
    "sub_test = pd.DataFrame(columns=[0, 1, 2, 3, 4])\n",
    "sub_test.insert(0, 'index', test_df.index)\n",
    "\n",
    "print('CV started')\n",
    "for train_index, dev_index in skf.split(docs, y):\n",
    "    X_train, X_dev = docs[train_index], docs[dev_index]\n",
    "    y_train, y_dev = to_categorical(y)[train_index], to_categorical(y)[dev_index]\n",
    "    \n",
    "    model = create_model()\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                     batch_size=32,\n",
    "                     validation_data=(X_dev, y_dev),\n",
    "                     epochs=epochs,\n",
    "                     callbacks=[es, mc])\n",
    "    pred_dev   = model.predict_proba(X_dev)\n",
    "    pred_test += model.predict_proba(docs_test)\n",
    "    \n",
    "    pred_train[dev_index, :] = pred_dev\n",
    "    cv_scores.append(metrics.log_loss(y_dev, pred_dev))\n",
    "    print('.', end='')\n",
    "\n",
    "print('')\n",
    "print(\"Mean CV LogLoss: %.3f\" % (np.mean(cv_scores)))\n",
    "pred_test /= cv\n",
    "\n",
    "sub_train[0] = pred_train[:, 0]\n",
    "sub_train[1] = pred_train[:, 1]\n",
    "sub_train[2] = pred_train[:, 2]\n",
    "sub_train[3] = pred_train[:, 3]\n",
    "sub_train[4] = pred_train[:, 4]\n",
    "\n",
    "sub_test[0] = pred_test[:, 0]\n",
    "sub_test[1] = pred_test[:, 1]\n",
    "sub_test[2] = pred_test[:, 2]\n",
    "sub_test[3] = pred_test[:, 3]\n",
    "sub_test[4] = pred_test[:, 4]\n",
    "\n",
    "sub_train.to_csv('submission3_train.csv', index=False)\n",
    "sub_test.to_csv('submission3_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/nzw0301/simple-keras-fasttext-val-loss-0-31"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
